{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10113427,"sourceType":"datasetVersion","datasetId":6239613}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import accuracy_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:19:39.539613Z","iopub.execute_input":"2024-12-05T13:19:39.540306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#loading the dataset from the drive\n!pip install gdown --quiet\n!gdown https://drive.google.com/uc?id=1T6bEwBtR4cdt8T_vGjB6LQ5MMnUMBMWB","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:19:54.848586Z","iopub.execute_input":"2024-12-05T13:19:54.849276Z","iopub.status.idle":"2024-12-05T13:20:27.364696Z","shell.execute_reply.started":"2024-12-05T13:19:54.849240Z","shell.execute_reply":"2024-12-05T13:20:27.363760Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1T6bEwBtR4cdt8T_vGjB6LQ5MMnUMBMWB\nFrom (redirected): https://drive.google.com/uc?id=1T6bEwBtR4cdt8T_vGjB6LQ5MMnUMBMWB&confirm=t&uuid=7e7f368d-1e65-404a-99c6-b48403cba8f6\nTo: /kaggle/working/rename.zip\n100%|███████████████████████████████████████| 2.00G/2.00G [00:17<00:00, 112MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!unzip -q -o rename.zip -d Rice_Crop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:20:32.969131Z","iopub.execute_input":"2024-12-05T13:20:32.969900Z","iopub.status.idle":"2024-12-05T13:20:50.582501Z","shell.execute_reply.started":"2024-12-05T13:20:32.969864Z","shell.execute_reply":"2024-12-05T13:20:50.581483Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"main_dir = \"Rice_Crop\"\nclasses = sorted([d for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))])\nprint(classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:21:00.936922Z","iopub.execute_input":"2024-12-05T13:21:00.937812Z","iopub.status.idle":"2024-12-05T13:21:00.993842Z","shell.execute_reply.started":"2024-12-05T13:21:00.937758Z","shell.execute_reply":"2024-12-05T13:21:00.992790Z"}},"outputs":[{"name":"stdout","text":"['Rice___Brown_Spot', 'Rice___Healthy', 'Rice___Leaf_Blast', 'Rice___Neck_Blast']\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\n# Data augmentation and normalization for training, only normalization for testing\ntransform_train = transforms.Compose([\n    transforms.RandomRotation(15),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:21:23.684475Z","iopub.execute_input":"2024-12-05T13:21:23.684815Z","iopub.status.idle":"2024-12-05T13:21:23.691065Z","shell.execute_reply.started":"2024-12-05T13:21:23.684786Z","shell.execute_reply":"2024-12-05T13:21:23.690116Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(main_dir, transform=transform_train)\n\n# Split the dataset into 90% training and 10% validation\ntrain_size = int(0.9 * len(train_dataset))\ntest_size = len(train_dataset) - train_size\ntrain_dataset, _ = random_split(train_dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n\n# Apply transform_test to the test dataset\ntest_dataset = datasets.ImageFolder(main_dir, transform=transform_test)\n_, test_dataset = random_split(test_dataset, [train_size, test_size])\ntest_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:22:10.794796Z","iopub.execute_input":"2024-12-05T13:22:10.795608Z","iopub.status.idle":"2024-12-05T13:22:10.845010Z","shell.execute_reply.started":"2024-12-05T13:22:10.795574Z","shell.execute_reply":"2024-12-05T13:22:10.844349Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n\n# Freeze all layers except the last one\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace the last fully connected layer for our custom output size\nmodel.fc = nn.Sequential(\n    nn.Linear(model.fc.in_features, 256),\n    nn.ReLU(),\n    nn.Linear(256, len(classes))\n)\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:22:44.849417Z","iopub.execute_input":"2024-12-05T13:22:44.850222Z","iopub.status.idle":"2024-12-05T13:22:46.255166Z","shell.execute_reply.started":"2024-12-05T13:22:44.850189Z","shell.execute_reply":"2024-12-05T13:22:46.254461Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 185MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# AdamW optimizer\noptimizer = optim.AdamW(model.parameters(), lr=1e4)#0.00001\n\n# Loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Training loop\nnum_epochs = 120\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    total = 0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.size(0)\n        _, preds = torch.max(outputs, 1)\n        running_corrects += torch.sum(preds == labels.data)\n        total += labels.size(0)\n    \n    train_loss = running_loss / total\n    train_accuracy = running_corrects.double() / total\n\n    model.eval()\n    running_corrects = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            total += labels.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n    \n    test_accuracy = running_corrects.double() / total\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n\ntorch.save(model.state_dict(), \"Rice_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:23:36.455765Z","iopub.execute_input":"2024-12-05T13:23:36.456465Z","iopub.status.idle":"2024-12-05T19:44:32.310895Z","shell.execute_reply.started":"2024-12-05T13:23:36.456433Z","shell.execute_reply":"2024-12-05T19:44:32.310031Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/120\nTrain Loss: inf, Train Accuracy: 0.2316\nTest Accuracy: 0.2255\nEpoch 2/120\nTrain Loss: nan, Train Accuracy: 0.1627\nTest Accuracy: 0.1691\nEpoch 3/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 4/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 5/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 6/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 7/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 8/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 9/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 10/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 11/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 12/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 13/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 14/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 15/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 16/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 17/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 18/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 19/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 20/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 21/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 22/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 23/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 24/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 25/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 26/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 27/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 28/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 29/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 30/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 31/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 32/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 33/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 34/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 35/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 36/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 37/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 38/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 39/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 40/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 41/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 42/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 43/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 44/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 45/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 46/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 47/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 48/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 49/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 50/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 51/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 52/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 53/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 54/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 55/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 56/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 57/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 58/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 59/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 60/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 61/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 62/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 63/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 64/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 65/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 66/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 67/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 68/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 69/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 70/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 71/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 72/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 73/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 74/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 75/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 76/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 77/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 78/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 79/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 80/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 81/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 82/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 84/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 85/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 86/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 87/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 88/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 89/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 90/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 91/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 92/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 93/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 94/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 95/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 96/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 97/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 98/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 99/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 100/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 101/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 102/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 103/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 104/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 105/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 106/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 107/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 108/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 109/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 110/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 111/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 112/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 113/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 114/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 115/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 116/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 117/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 118/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 119/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\nEpoch 120/120\nTrain Loss: nan, Train Accuracy: 0.1507\nTest Accuracy: 0.1691\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T19:45:23.254189Z","iopub.execute_input":"2024-12-05T19:45:23.254918Z","iopub.status.idle":"2024-12-05T19:45:24.285467Z","shell.execute_reply.started":"2024-12-05T19:45:23.254881Z","shell.execute_reply":"2024-12-05T19:45:24.284554Z"}},"outputs":[{"name":"stdout","text":"Rice_Crop  Rice_model.pth  rename.zip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%cd Rice_Crop/Rice___Brown_Spot/IMG_20190419_095712.jpg\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T19:45:29.054281Z","iopub.execute_input":"2024-12-05T19:45:29.054708Z","iopub.status.idle":"2024-12-05T19:45:30.089569Z","shell.execute_reply.started":"2024-12-05T19:45:29.054672Z","shell.execute_reply":"2024-12-05T19:45:30.088390Z"}},"outputs":[{"name":"stdout","text":"[Errno 20] Not a directory: 'Rice_Crop/Rice___Brown_Spot/IMG_20190419_095712.jpg'\n/kaggle/working\nRice_Crop  Rice_model.pth  rename.zip\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%cd ../..\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T19:45:33.894542Z","iopub.execute_input":"2024-12-05T19:45:33.895507Z","iopub.status.idle":"2024-12-05T19:45:34.983316Z","shell.execute_reply.started":"2024-12-05T19:45:33.895457Z","shell.execute_reply":"2024-12-05T19:45:34.982139Z"}},"outputs":[{"name":"stdout","text":"/\n'=24.4'\t\t\t\t\t    libx32\n NGC-DL-CONTAINER-LICENSE\t\t    media\n bin\t\t\t\t\t    mnt\n boot\t\t\t\t\t    opt\n cuda-keyring_1.0-1_all.deb\t\t    proc\n dev\t\t\t\t\t    root\n entrypoint.sh\t\t\t\t    run\n etc\t\t\t\t\t    run_jupyter.sh\n home\t\t\t\t\t    sbin\n install_packages.sh\t\t\t    srv\n kaggle\t\t\t\t\t    sys\n lib\t\t\t\t\t    tmp\n lib32\t\t\t\t\t    usr\n lib64\t\t\t\t\t    var\n libnvinfer8_8.6.1.6-1+cuda12.0_amd64.deb\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom PIL import Image\n\n# Path to the image you want to test (replace with your image file path)\nimage_path = r\"/kaggle/input/rice-disease-detection/Rice___Brown_Spot/IMG_20190419_095715.jpg\"  # Specify the image file path\n\n# Load the saved model\nmodel = models.resnet50(pretrained=False)  # Don't load pretrained weights, we have our model\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Sequential(\n    nn.Linear(model.fc.in_features, 256),\n    nn.ReLU(),\n    nn.Linear(256, len(classes))\n)\n\nmodel.load_state_dict(torch.load(r\"/kaggle/working/Rice_model.pth\"))\nmodel = model.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:08:11.356771Z","iopub.execute_input":"2024-12-05T20:08:11.357227Z","iopub.status.idle":"2024-12-05T20:08:11.905888Z","shell.execute_reply.started":"2024-12-05T20:08:11.357193Z","shell.execute_reply":"2024-12-05T20:08:11.905013Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/4193903798.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(r\"/kaggle/working/Rice_model.pth\"))\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=2048, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=4, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"transform_test = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load the image and apply transformations\nimage = Image.open(image_path)\nimage = transform_test(image).unsqueeze(0).to(device) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:08:26.374936Z","iopub.execute_input":"2024-12-05T20:08:26.375681Z","iopub.status.idle":"2024-12-05T20:08:26.391547Z","shell.execute_reply.started":"2024-12-05T20:08:26.375645Z","shell.execute_reply":"2024-12-05T20:08:26.390742Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Get the model's prediction\nwith torch.no_grad():\n    outputs = model(image)\n    _, predicted_class = torch.max(outputs, 1)\n\n# Map the predicted class index to the actual class label\npredicted_label = classes[predicted_class.item()]\nprint(f\"Predicted class: {predicted_label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:08:30.854938Z","iopub.execute_input":"2024-12-05T20:08:30.855744Z","iopub.status.idle":"2024-12-05T20:08:30.929249Z","shell.execute_reply.started":"2024-12-05T20:08:30.855712Z","shell.execute_reply":"2024-12-05T20:08:30.928403Z"}},"outputs":[{"name":"stdout","text":"Predicted class: Rice___Brown_Spot\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"predicted_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:08:35.684716Z","iopub.execute_input":"2024-12-05T20:08:35.685506Z","iopub.status.idle":"2024-12-05T20:08:35.693250Z","shell.execute_reply.started":"2024-12-05T20:08:35.685472Z","shell.execute_reply":"2024-12-05T20:08:35.692336Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([0], device='cuda:0')"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:09:29.145236Z","iopub.execute_input":"2024-12-05T20:09:29.145874Z","iopub.status.idle":"2024-12-05T20:09:29.727024Z","shell.execute_reply.started":"2024-12-05T20:09:29.145842Z","shell.execute_reply":"2024-12-05T20:09:29.726173Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"#!pip install huggingface_hub\nfrom huggingface_hub import login\nfrom huggingface_hub import HfApi, Repository\nimport torch\n\n# Replace 'your_huggingface_token' with your token\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:16:00.775665Z","iopub.execute_input":"2024-12-05T20:16:00.776430Z","iopub.status.idle":"2024-12-05T20:16:00.829900Z","shell.execute_reply.started":"2024-12-05T20:16:00.776392Z","shell.execute_reply":"2024-12-05T20:16:00.829052Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Save your model\ntorch.save(model.state_dict(), \"Rice_model.pth\")\n\n\n# Replace with your desired repository name\nrepo_name = \"Rice-Disease-Detection\"\n\n# Initialize repository\nrepo = Repository(local_dir=\"model_repo\", clone_from=f\"Subh775/{repo_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T20:16:22.180117Z","iopub.execute_input":"2024-12-05T20:16:22.180468Z","iopub.status.idle":"2024-12-05T20:16:22.464444Z","shell.execute_reply.started":"2024-12-05T20:16:22.180437Z","shell.execute_reply":"2024-12-05T20:16:22.463524Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\n/model_repo is already a clone of https://huggingface.co/Subh775/Rice-Disease-Detection. Make sure you pull the latest changes with `repo.git_pull()`.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Move your model into the repository folder\nimport shutil\nimport os \ndestination_path = os.path.join(\"model_repo\", \"Rice_model.pth\")\n#shutil.move(\"Rice_model.pth\", \"model_repo/\")\nshutil.copy(\"Rice_model.pth\", destination_path)\n\n\n# Add README or other files if needed\n#with open(\"model_repo/README.md\", \"w\") as f:\n#    f.write(\"# Rice Disease Detection Model\\nThis model was trained to detect diseases in rice crops.\")\n\n# Commit and push\nrepo.push_to_hub(commit_message=\"Initial model upload\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}